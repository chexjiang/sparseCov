loss[5,k,i] = norm(s4 - data.true.cov, type='2')
# Record TPR and FRR
TPR[5,k,i] = sum(s4!=0 & data.true.cov!=0) / sum(data.true.cov!=0)
FPR[5,k,i] = sum(s4!=0 & data.true.cov==0) / sum(data.true.cov==0)
}
}
res = list(operator=op, loss=loss, TPR=TPR, FPR=FPR, time=time, delta=delta, lambda=lambda)
View(res)
res[["delta"]]
res[["loss"]]
save(res, file=paste0('simu/res.qiu.cv.oracle2.', op, '.RData'))
# Compute the average (standard error) operator norm loss for 5 methods
apply(res$loss, 1, colMeans)
# delta
apply(res$delta, 1, colMeans)
n
pdf(file='simu/cv-oracle2-diag.pdf', width=8, height=7)
par(mfrow=c(2,2))
for(i in 1:length(p.list)){
plot(1:nrep, res$delta[1,,i],
main=paste0('(', i, ') p=', p.list[i]),
ylab=expression(delta),
xlab='Replicate',
ylim=c(0.9, 2), pch=16)
points(1:nrep, res$delta[3,,i], pch=18, col='blue')
points(1:nrep, res$delta[3,,i], pch=17, col='red')
legend('bottomright',
legend=c("CV estimate", "CV oracle estimate", "Oracle estimate"),
col=c('black', 'blue', 'red'), pch=c(16,18,17))
if(i==1) mtext(side=3, line=2, at=1, adj=0, cex=1.5, 'n=500')
}
dev.off()
pdf(file='simu/cv-oracle2-diag.pdf', width=8, height=7)
par(mfrow=c(2,2))
for(i in 1:length(p.list)){
plot(1:nrep, res$delta[1,,i],
main=paste0('(', i, ') p=', p.list[i]),
ylab=expression(delta),
xlab='Replicate',
ylim=c(0.9, 2), pch=16)
points(1:nrep, res$delta[3,,i], pch=18, col='blue')
points(1:nrep, res$delta[4,,i], pch=17, col='red')
legend('bottomright',
legend=c("CV estimate", "CV oracle estimate", "Oracle estimate"),
col=c('black', 'blue', 'red'), pch=c(16,18,17))
if(i==1) mtext(side=3, line=2, at=1, adj=0, cex=1.5, 'n=500')
}
dev.off()
p.list = p.list*2
pdf(file='simu/cv-oracle2-diag.pdf', width=8, height=7)
par(mfrow=c(2,2))
for(i in 1:length(p.list)){
plot(1:nrep, res$delta[1,,i],
main=paste0('(', i, ') p=', p.list[i]),
ylab=expression(delta),
xlab='Replicate',
ylim=c(0.9, 2), pch=16)
points(1:nrep, res$delta[3,,i], pch=18, col='blue')
points(1:nrep, res$delta[4,,i], pch=17, col='red')
legend('bottomright',
legend=c("CV estimate", "CV oracle estimate", "Oracle estimate"),
col=c('black', 'blue', 'red'), pch=c(16,18,17))
if(i==1) mtext(side=3, line=2, at=1, adj=0, cex=1.5, 'n=2000')
}
dev.off()
p.list
p.list = c(300, 600, 1200, 2400)
pdf(file='simu/cv-oracle2-diag.pdf', width=8, height=7)
par(mfrow=c(2,2))
for(i in 1:length(p.list)){
plot(1:nrep, res$delta[1,,i],
main=paste0('(', i, ') p=', p.list[i]),
ylab=expression(delta),
xlab='Replicate',
ylim=c(0.9, 2), pch=16)
points(1:nrep, res$delta[3,,i], pch=18, col='blue')
points(1:nrep, res$delta[4,,i], pch=17, col='red')
legend('bottomright',
legend=c("CV estimate", "CV oracle estimate", "Oracle estimate"),
col=c('black', 'blue', 'red'), pch=c(16,18,17))
if(i==1) mtext(side=3, line=2, at=1, adj=0, cex=1.5, 'n=1000')
}
dev.off()
source("~/Documents/research/omicDesigner/sparseCov-old/cv.R")
# large size
n = 100
nrep = 50
p.list=c(30, 60, 120, 300)
op = 'diag'
start.time0 <- Sys.time()
cat(paste0("Operator: ", op, '.\n'))
# The matrix to record loss, dim = 6*50*4
# dim 1: 3 method
# dim 2: 50 replicates
# dim 3: 4 values of p in p.list
loss = array(NA, dim=c(5, nrep, length(p.list)))
# The ability to recover sparsity --
# The TPR (true positive rate) matrix
TPR = array(NA, dim=c(5, nrep, length(p.list)))
# The FPR (false positive rate) matrix
FPR = array(NA, dim=c(5, nrep, length(p.list)))
# The running time of each method
time = array(NA, dim=c(5, nrep, length(p.list)))
# The thr level for all
delta = array(NA, dim=c(4, nrep, length(p.list)))
lambda = array(NA, dim=c(4, nrep, length(p.list)))
# Iterate over p.list
for(i in 1:length(p.list)){
# Make covaiance matrix
p = p.list[i]
cat(paste0("The ", i, "th value of p: p = ", p,'\n'))
# specify a covariance structure
if(op=='ma'){
data.true.cov = ma1.true.cov(p)
}else if(op=='diag'){
data.true.cov = block.true.cov(p)
}else if(op=='ar'){
data.true.cov = ar1.true.cov(p)
}else{
stop('No valid covariance structure!')
}
# Generate nrep=50 replicates sample data
for (k in 1:nrep){
if(k %% 10 == 0) cat(paste0("  In ", k, "th replicate.\n"))
# Simulate data (n=sample size, p=variant number)
data = sampleMVN.sparse(n, data.true.cov)
#data = sampleMVN(n, data.true.cov, n_cores=1, fastmvn=TRUE)
## Without thresholding, simply use the sample covariance to estimate covariance
start.time <- Sys.time()
sample.cov = Rfast::cova(data, large = TRUE)
end.time <- Sys.time()
time[1,k,i] <- end.time - start.time
# Record loss: the risk between s and the true covariance matrix
loss[1,k,i] = norm(sample.cov - data.true.cov, type='2')
TPR[1,k,i] = 1
# Hard Thresholding: Tune delta by CV.est
start.time <- Sys.time()
delta1 = cv.min(data, operator='hard')
delta[1,k,i] = delta1
# Record the thr level for cv selection
lambda[1,k,i] = sqrt(log(p)/n)*delta1
# Compute the thresholing estimator
s1 = s_hard(sample.cov, delta1, n=n)
end.time <- Sys.time()
time[2,k,i] <- end.time - start.time
# Record loss: the risk between s and the true covariance matrix
loss[2,k,i] = norm(s1 - data.true.cov, type='2')
# Record TPR and FPR
TPR[2,k,i] = sum(s1!=0 & data.true.cov!=0) / sum(data.true.cov!=0)
FPR[2,k,i] = sum(s1!=0 & data.true.cov==0) / sum(data.true.cov==0)
# Hard Thresholding: Tune delta by CV.est
start.time <- Sys.time()
delta2 = cv.truth(data, method='hard', data.true.cov)
delta[2,k,i] = delta2
# Record the thr level for cv selection
lambda[2,k,i] = sqrt(log(p)/n)*delta2
# Compute the thresholing estimator
s2 = s_hard(sample.cov, delta2, n=n)
end.time <- Sys.time()
time[3,k,i] <- end.time - start.time
# Record loss: the risk between s and the true covariance matrix
loss[3,k,i] = norm(s2 - data.true.cov, type='2')
# Record TPR and FPR
TPR[3,k,i] = sum(s2!=0 & data.true.cov!=0) / sum(data.true.cov!=0)
FPR[3,k,i] = sum(s2!=0 & data.true.cov==0) / sum(data.true.cov==0)
# Hard Thresholding: Tune delta by Qiu selection
start.time <- Sys.time()
delta3 = qiu_select(data, sample.cov)
delta[3,k,i] = delta3
# Record the thr level for Qiu selection
lambda[3,k,i] = sqrt(log(p)/n)*delta3
# Compute the thresholing estimator
s3 = s_hard(sample.cov, delta3, n=n)
end.time <- Sys.time()
time[4,k,i] <- end.time - start.time
# Record loss: the risk between s and the true covariance matrix
loss[4,k,i] = norm(s3 - data.true.cov, type='2')
# Record TPR and FPR
TPR[4,k,i] = sum(s3!=0 & data.true.cov!=0) / sum(data.true.cov!=0)
FPR[4,k,i] = sum(s3!=0 & data.true.cov==0) / sum(data.true.cov==0)
# Hard Tr
delta4 = oracle.min(data, 'hard', data.true.cov)
delta[4,k,i] = delta4
# Record the thr level
lambda[4,k,i] = sqrt(log(p)/n)*delta4
# Compute the thresholing estimator
s4 = s_hard(sample.cov, delta4, n=n)
end.time <- Sys.time()
time[5,k,i] <- end.time - start.time
# Record loss: the risk between s and the true covariance matrix
loss[5,k,i] = norm(s4 - data.true.cov, type='2')
# Record TPR and FRR
TPR[5,k,i] = sum(s4!=0 & data.true.cov!=0) / sum(data.true.cov!=0)
FPR[5,k,i] = sum(s4!=0 & data.true.cov==0) / sum(data.true.cov==0)
}
}
res = list(operator=op, loss=loss, TPR=TPR, FPR=FPR, time=time, delta=delta, lambda=lambda)
# Compute the average (standard error) operator norm loss for 5 methods
apply(res$loss, 1, colMeans)
# lambda.
apply(res$lambda, 1, colMeans)
# delta
apply(res$delta, 1, colMeans)
p.list = c(300, 600, 1200, 2400)
pdf(file='simu/cv-oracle22-diag.pdf', width=8, height=7)
par(mfrow=c(2,2))
for(i in 1:length(p.list)){
plot(1:nrep, res$delta[1,,i],
main=paste0('(', i, ') p=', p.list[i]),
ylab=expression(delta),
xlab='Replicate',
ylim=c(0.9, 2), pch=16)
points(1:nrep, res$delta[3,,i], pch=18, col='blue')
points(1:nrep, res$delta[4,,i], pch=17, col='red')
legend('bottomright',
legend=c("CV estimate", "CV oracle estimate", "Oracle estimate"),
col=c('black', 'blue', 'red'), pch=c(16,18,17))
if(i==1) mtext(side=3, line=2, at=1, adj=0, cex=1.5, 'n=1000')
}
dev.off()
# large size
n = 300
nrep = 50
p.list=c(100, 200, 400, 600)
op = 'ma'
start.time0 <- Sys.time()
cat(paste0("Operator: ", op, '.\n'))
# The matrix to record loss, dim = 6*50*4
# dim 1: 3 method
# dim 2: 50 replicates
# dim 3: 4 values of p in p.list
loss = array(NA, dim=c(5, nrep, length(p.list)))
# The ability to recover sparsity --
# The TPR (true positive rate) matrix
TPR = array(NA, dim=c(5, nrep, length(p.list)))
# The FPR (false positive rate) matrix
FPR = array(NA, dim=c(5, nrep, length(p.list)))
# The running time of each method
time = array(NA, dim=c(5, nrep, length(p.list)))
# The thr level for all
delta = array(NA, dim=c(4, nrep, length(p.list)))
lambda = array(NA, dim=c(4, nrep, length(p.list)))
# Iterate over p.list
for(i in 1:length(p.list)){
# Make covaiance matrix
p = p.list[i]
cat(paste0("The ", i, "th value of p: p = ", p,'\n'))
# specify a covariance structure
if(op=='ma'){
data.true.cov = ma1.true.cov(p)
}else if(op=='diag'){
data.true.cov = block.true.cov(p)
}else if(op=='ar'){
data.true.cov = ar1.true.cov(p)
}else{
stop('No valid covariance structure!')
}
# Generate nrep=50 replicates sample data
for (k in 1:nrep){
if(k %% 10 == 0) cat(paste0("  In ", k, "th replicate.\n"))
# Simulate data (n=sample size, p=variant number)
data = sampleMVN.sparse(n, data.true.cov)
#data = sampleMVN(n, data.true.cov, n_cores=1, fastmvn=TRUE)
## Without thresholding, simply use the sample covariance to estimate covariance
start.time <- Sys.time()
sample.cov = Rfast::cova(data, large = TRUE)
end.time <- Sys.time()
time[1,k,i] <- end.time - start.time
# Record loss: the risk between s and the true covariance matrix
loss[1,k,i] = norm(sample.cov - data.true.cov, type='2')
TPR[1,k,i] = 1
# Hard Thresholding: Tune delta by CV.est
start.time <- Sys.time()
delta1 = cv.min(data, operator='hard')
delta[1,k,i] = delta1
# Record the thr level for cv selection
lambda[1,k,i] = sqrt(log(p)/n)*delta1
# Compute the thresholing estimator
s1 = s_hard(sample.cov, delta1, n=n)
end.time <- Sys.time()
time[2,k,i] <- end.time - start.time
# Record loss: the risk between s and the true covariance matrix
loss[2,k,i] = norm(s1 - data.true.cov, type='2')
# Record TPR and FPR
TPR[2,k,i] = sum(s1!=0 & data.true.cov!=0) / sum(data.true.cov!=0)
FPR[2,k,i] = sum(s1!=0 & data.true.cov==0) / sum(data.true.cov==0)
# Hard Thresholding: Tune delta by CV.est
start.time <- Sys.time()
delta2 = cv.truth(data, method='hard', data.true.cov)
delta[2,k,i] = delta2
# Record the thr level for cv selection
lambda[2,k,i] = sqrt(log(p)/n)*delta2
# Compute the thresholing estimator
s2 = s_hard(sample.cov, delta2, n=n)
end.time <- Sys.time()
time[3,k,i] <- end.time - start.time
# Record loss: the risk between s and the true covariance matrix
loss[3,k,i] = norm(s2 - data.true.cov, type='2')
# Record TPR and FPR
TPR[3,k,i] = sum(s2!=0 & data.true.cov!=0) / sum(data.true.cov!=0)
FPR[3,k,i] = sum(s2!=0 & data.true.cov==0) / sum(data.true.cov==0)
# Hard Thresholding: Tune delta by Qiu selection
start.time <- Sys.time()
delta3 = qiu_select(data, sample.cov)
delta[3,k,i] = delta3
# Record the thr level for Qiu selection
lambda[3,k,i] = sqrt(log(p)/n)*delta3
# Compute the thresholing estimator
s3 = s_hard(sample.cov, delta3, n=n)
end.time <- Sys.time()
time[4,k,i] <- end.time - start.time
# Record loss: the risk between s and the true covariance matrix
loss[4,k,i] = norm(s3 - data.true.cov, type='2')
# Record TPR and FPR
TPR[4,k,i] = sum(s3!=0 & data.true.cov!=0) / sum(data.true.cov!=0)
FPR[4,k,i] = sum(s3!=0 & data.true.cov==0) / sum(data.true.cov==0)
# Hard Tr
delta4 = oracle.min(data, 'hard', data.true.cov)
delta[4,k,i] = delta4
# Record the thr level
lambda[4,k,i] = sqrt(log(p)/n)*delta4
# Compute the thresholing estimator
s4 = s_hard(sample.cov, delta4, n=n)
end.time <- Sys.time()
time[5,k,i] <- end.time - start.time
# Record loss: the risk between s and the true covariance matrix
loss[5,k,i] = norm(s4 - data.true.cov, type='2')
# Record TPR and FRR
TPR[5,k,i] = sum(s4!=0 & data.true.cov!=0) / sum(data.true.cov!=0)
FPR[5,k,i] = sum(s4!=0 & data.true.cov==0) / sum(data.true.cov==0)
}
}
res = list(operator=op, loss=loss, TPR=TPR, FPR=FPR, time=time, delta=delta, lambda=lambda)
p.list = c(300, 600, 1200, 2400)
pdf(file='simu/cv-oracle2-ma.pdf', width=8, height=7)
par(mfrow=c(2,2))
for(i in 1:length(p.list)){
plot(1:nrep, res$delta[1,,i],
main=paste0('(', i, ') p=', p.list[i]),
ylab=expression(delta),
xlab='Replicate',
ylim=c(0.9, 2), pch=16)
points(1:nrep, res$delta[3,,i], pch=18, col='blue')
points(1:nrep, res$delta[4,,i], pch=17, col='red')
legend('bottomright',
legend=c("CV estimate", "CV oracle estimate", "Oracle estimate"),
col=c('black', 'blue', 'red'), pch=c(16,18,17))
if(i==1) mtext(side=3, line=2, at=1, adj=0, cex=1.5, 'n=1000')
}
dev.off()
install.packages(c("devtools", "roxygen2", "testthat", "knitr"))
library('devtools')
setwd("~/Documents/research/omicDesigner")
create('~/sparseCov')
setwd('~/sparseCov')
dir()
getwd()
setwd("~/Documents/research/omicDesigner")
create('~/sparseCov')
getwd()
setwd('~/sparseCov')
create('/sparseCov')
create('sparseCov')
create('sparseCorr')
setwd('~/sparseCov')
install.packages("WGCNA")
library(WGCNA)
BiocManager::install("GO.db")
library(WGCNA)
BiocManager::install("impute")
library(WGCNA)
BiocManager::install("preprocessCore")
library(WGCNA)
# simulate data (n=sample size, p=variant number)
n <- 10
p <- 10
data.true.cov <- ma1.true.cov(p)
data <- sampleMVN(n, data.true.cov, sparse=TRUE, fastmvn=F)
sampleMVN <- function(n,
Sigma,
sparse=TRUE,
n_cores = 1,
fastmvn = FALSE) {
if(sparse){
mvnrv <- sampleMVN.sparse(n, Sigma)
}else{
if(fastmvn) {
mvnrv <- mvnfast::rmvn(n, mu = rep(0, dim(Sigma)[1]), sigma = Sigma, ncores = n_cores)
} else {
mvnrv <-
rmvnorm(n, mean = rep(0, dim(Sigma)[1]), sigma = Sigma, checkSymmetry = FALSE, method="eigen")
}
}
#mvnrvq <- apply(mvnrv, 2, stats::pnorm)
return(mvnrv)
}
## Sparse version
sampleMVN.sparse <- function(n, Sigma){
CH <- Matrix::Cholesky(as(Sigma, 'dsCMatrix'))
p <- dim(Sigma)[1]
mvnrv <- sparseMVN::rmvn.sparse(n=n, rep(0,p), CH, prec=FALSE)
return(mvnrv)
}
data <- sampleMVN(n, data.true.cov, sparse=TRUE, fastmvn=F)
# compute the thresholding estimator
s <- est_threshold(data, method='qiu', operator = 'soft', corr=T)
est_threshold <- function(data,
method=c('cv', 'qiu'),
operator=c('hard', 'soft', 'scad', 'al'),
corr=TRUE){
p <- dim(data)[1]
n <- dim(data)[2]
# sample covariance
z <- Rfast::cova(data) *(n-1)/n
# select the optimal thresholding level
delta <- est.delta(data, method=method, operator=operator)
s <- thresh_op(z, operator=operator, delta=delta, n=n)
# Modify s to make it psd
tol <- 1e-6
ev <- eigen(s, symmetric=TRUE, only.values = TRUE)$values
s1 <- s + (tol-min(ev))*diag(dim(s)[1])
if(corr){
# make corr
s1_corr <- cov2cor(s1)
output <- s1_corr
}else{
output <- s1
}
return(output)
}
# compute the thresholding estimator
s <- est_threshold(data, method='qiu', operator = 'soft', corr=T)
est.delta = function(data,
method=c('cv', 'qiu'),
operator=c('hard', 'soft', 'scad', 'al')){
if((method=='qiu') ){
s <- Rfast::cova(data) *(n-1)/n
delta <- qiu.select(data, s)
}else if(method=='cv'){
delta <- cv.min(data, operator)
}else{
stop('Please specify a valid thresholding method and an operator function.')
}
return(delta)
}
# compute the thresholding estimator
s <- est_threshold(data, method='qiu', operator = 'soft', corr=T)
s
# simulate data (n=sample size, p=variant number)
n <- 10
p <- 12
data.true.cov <- block.true.cov(p)
View(data.true.cov)
data.true.cov <- block.true.cov(p)
data <- sampleMVN(n, data.true.cov, sparse=TRUE, fastmvn=F)
# compute the thresholding estimator
s <- est_threshold(data, method='qiu', operator = 'soft', corr=F)
s
View(s)
# compute the thresholding estimator
s <- est_threshold(data, method='cv', operator = 'soft', corr=F)
s
View(s)
# simulate data (n=sample size, p=variant number)
n <- 10
# simulate data (n=sample size, p=variant number)
n <- 10
p <- 15
data.true.cov <- block.true.cov(p)
data <- sampleMVN(n, data.true.cov, sparse=TRUE)
# compute the thresholding estimator
s <- est_threshold(data, method='cv', operator = 'soft', corr=F)
s
View(s)
# simulate data (n=sample size, p=variant number)
n <- 20
p <- 15
data.true.cov <- block.true.cov(p)
data <- sampleMVN(n, data.true.cov, sparse=TRUE)
# compute the thresholding estimator
s <- est_threshold(data, method='cv', operator = 'soft', corr=F)
s
View(s)
View(data.true.cov)
# simulate data (n=sample size, p=variant number)
n <- 50
p <- 30
data.true.cov <- block.true.cov(p)
data <- sampleMVN(n, data.true.cov, sparse=TRUE)
# compute the thresholding estimator
s <- est_threshold(data, method='cv', operator = 'soft', corr=F)
s
View(s)
View(data.true.cov)
# compute the thresholding estimator
s <- est_threshold(data, method='cv', operator='scad', corr=F)
s
View(s.cv)
# simulate data (n=sample size, p=variant number)
n <- 50
p <- 30
data.true.cov <- block.true.cov(p)
data <- sampleMVN(n, data.true.cov, sparse=TRUE)
# compute the thresholding estimator
s <- est_threshold(data, method='cv', operator='scad', corr=F)
s
source("~/sparseCov/R/makeCov.R")
setwd("~/sparseCov/R")
library('devtools')
load_all()
setwd("~/sparseCov")
load_all()
